{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习实验六 --决策树\n",
    " \n",
    "\n",
    "## 实验要求\n",
    "- 基本要求\n",
    "    1. 基于 Watermelon-train1数据集（只有离散属性），构造ID3决策树；\n",
    "    2. 基于构造的 ID3 决策树，对数据集 Watermelon-test1进行预测，输出分类精度；\n",
    "- 中级要求\n",
    "    1. 对数据集Watermelon-train2，构造C4.5或者CART决策树，要求可以处理连续型属性；\n",
    "    2. 对测试集Watermelon-test2进行预测，输出分类精度；\n",
    "\n",
    "\n",
    "## 导入数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import math\n",
    "import copy\n",
    "def readfile(name):\n",
    "    df = pd.read_csv(name, encoding = 'gbk')\n",
    "    temp = np.array(df).tolist()\n",
    "    for i in temp:\n",
    "        i.pop(0)\n",
    "    return temp\n",
    "\n",
    "train1 = readfile(\"Watermelon-train1.csv\")\n",
    "train2 = readfile(\"Watermelon-train2.csv\")\n",
    "test1 = readfile(\"Watermelon-test1.csv\")\n",
    "test2 = readfile(\"Watermelon-test2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['青绿', '蜷缩', '浊响', '清晰', 0.697, '是'], ['乌黑', '蜷缩', '沉闷', '清晰', 0.774, '是'], ['乌黑', '蜷缩', '浊响', '清晰', 0.634, '是'], ['青绿', '蜷缩', '沉闷', '清晰', 0.608, '是'], ['浅白', '蜷缩', '浊响', '清晰', 0.556, '是'], ['青绿', '稍蜷', '浊响', '清晰', 0.403, '是'], ['乌黑', '稍蜷', '浊响', '稍糊', 0.481, '是'], ['乌黑', '稍蜷', '浊响', '清晰', 0.437, '是'], ['乌黑', '稍蜷', '沉闷', '稍糊', 0.666, '否'], ['青绿', '硬挺', '清脆', '清晰', 0.243, '否'], ['浅白', '硬挺', '清脆', '模糊', 0.245, '否'], ['浅白', '蜷缩', '浊响', '模糊', 0.343, '否'], ['青绿', '稍蜷', '浊响', '稍糊', 0.639, '否'], ['浅白', '稍蜷', '沉闷', '稍糊', 0.657, '否'], ['乌黑', '稍蜷', '浊响', '清晰', 0.36, '否'], ['浅白', '蜷缩', '浊响', '模糊', 0.593, '否'], ['青绿', '蜷缩', '沉闷', '稍糊', 0.719, '否']]\n"
     ]
    }
   ],
   "source": [
    "print(train2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算信息增益\n",
    "- 统计某结果数据发生的频率，每项的信息以字典的形似存储\n",
    "- 计算信息熵\n",
    "- 返回信息熵和分类信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information(data):\n",
    "    dic = {}\n",
    "    for i in data:\n",
    "        current = i[-1] #取出最后的结果\n",
    "        if current not in dic.keys(): \n",
    "            dic[current] = 1 #创建一个新的类别\n",
    "        else:\n",
    "            dic[current] += 1 #原有类别+1\n",
    "    result = 0.0\n",
    "    for key in dic:\n",
    "        prob = float(dic[key]) / len(data)\n",
    "        result -= prob * math.log(prob,2) \n",
    "    return result, dic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 将数据按照某一种类的属性重新分类，并将该行属性删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data, index, kind):\n",
    "    ls = []\n",
    "    for temp in data:\n",
    "        if temp[index] == kind:\n",
    "            t = temp[0: index]\n",
    "            t = t + temp[index + 1: ]\n",
    "            ls.append(t)\n",
    "    return ls"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 计算信息熵和信息增益并返回最优的分类方式，对数据的每项指标做以下的过程\n",
    "    1. 抽取该项数据的所有信息\n",
    "    2. 按照该项数据的类别信息将数据集划分成多个子数据集\n",
    "    3. 计算每个数据集的信息熵\n",
    "    5. 计算该项数据的信息增益\n",
    "    6. 根据信息增益选择最好的分类项目，返回该项目的类别号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseBestFeatureToSplit(data):\n",
    "    base, mm= information(data) #原始的信息熵\n",
    "    best = 0\n",
    "    bestindex = -1\n",
    "    for i in range(len(data[0]) - 1):\n",
    "        #抽取该列数据的所有信息\n",
    "        ls = [index[i] for index in data]\n",
    "        feture = set(ls) \n",
    "        #计算该列的信息增益\n",
    "        temp = 0.0\n",
    "        for value in feture:\n",
    "            datatemp = split(data, i, value)\n",
    "            prob = len(datatemp) / float(len(data))\n",
    "            t, mm = information(datatemp)\n",
    "            temp += prob * t\n",
    "        infoGain = base - temp\n",
    "        #根据信息增益挑选 \n",
    "        if infoGain > best:\n",
    "            best = infoGain\n",
    "            bestindex = i\n",
    "    return bestindex "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 递归构建$ID3$决策树\n",
    "- 决策树的生成\n",
    "\t1. 从根节点开始，计算所有可能特征的信息增益，选择信息增益最大的特征作为划分该节点的特征，根据该特征的不同取值建立子节点；\n",
    "\t2. 在对子节点递归地调用以上方法，直到达到停止条件，得到⼀个决策树。\n",
    "- 迭代停止条件\n",
    "    1. 当前结点所有样本都属于同⼀类别；\n",
    "    2. 当前结点的所有属性值都相同，没有剩余属性可用来进一步划分样本；\n",
    "    3. 达到最大树深；\n",
    "    4. 达到叶子结点的最小样本数；\n",
    "- 具体实现\n",
    "    1. 首先取出该数据集的类别信息\n",
    "    2. 统计处类别信息以及数量，如果只有一个类别，返回该类别\n",
    "    3. 计算最优划分的索引\n",
    "    4. 初始化子树\n",
    "    5. 当前已经选择的特征不再参与分类，将该特征删除\n",
    "    6. 计算剩余特征的集合\n",
    "    7. 对于每个分支，进行递归\n",
    "    8. 返回值为子树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify1(data, labels):\n",
    "    typelist = [index[-1] for index in data] #取出该数据集的分类\n",
    "    nothing, typecount = information(data) #计算出类别种类以及数量\n",
    "    if len(typecount) == 1: #如果只有一个类别\n",
    "        return typelist[0]\n",
    "    bestindex = chooseBestFeatureToSplit(data)  # 最优划分属性的索引\n",
    "    bestlabel = labels[bestindex]\n",
    "    Tree = {bestlabel: {}}\n",
    "    temp = labels[:]\n",
    "    del (temp[bestindex])  # 已经选择的特征不再参与分类，将该类别删除\n",
    "    feature = [example[bestindex] for example in data]\n",
    "    unique = set(feature)  # 该属性所有可能取值，也就是节点的分支\n",
    "    for i in unique:  \n",
    "        temp = temp[:] \n",
    "        Tree[bestlabel][i] = classify1(split(data, bestindex, i), temp)\n",
    "    return Tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对测试集利用$ID3$决策树进行分类\n",
    "- 取出当前树的根节点\n",
    "- 利用跟节点信息查询当前输入数据输入内容\n",
    "- 如果查询出来的分支是叶节点，返回该值\n",
    "- 如果不是叶节点，递归查询子树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成决策树如下: {'纹理': {'模糊': '否', '稍糊': {'色泽': {'乌黑': {'敲声': {'沉闷': '否', '浊响': '是'}}, '浅白': '否', '青绿': '否'}}, '清晰': {'根蒂': {'稍蜷': '是', '蜷缩': '是', '硬挺': '否'}}}}\n"
     ]
    }
   ],
   "source": [
    "def run1(testdata, tree, labels):\n",
    "    firstStr = list(tree.keys())[0]\n",
    "    secondDict = tree[firstStr]\n",
    "    featIndex = labels.index(firstStr)\n",
    "    result = ''\n",
    "    for key in list(secondDict.keys()): \n",
    "         if testdata[featIndex] == key:\n",
    "            if type(secondDict[key]).__name__ == 'dict':  # 该分支不是叶子节点，递归\n",
    "                result = run1(testdata, secondDict[key], labels)\n",
    "            else:\n",
    "                result = secondDict[key]\n",
    "    return result\n",
    "\n",
    "def getresult(train, test, labels):\n",
    "    ls = []\n",
    "    tree = classify1(train, labels)\n",
    "    print(\"生成决策树如下:\", tree)\n",
    "    for index in test:\n",
    "        ls.append(run1(index, tree, labels))\n",
    "    return ls\n",
    "\n",
    "labels1 = ['色泽', '根蒂', '敲声', '纹理', '好瓜']\n",
    "result1 = getresult(train1, test1, labels1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID3分类器对于test1数据集的准确率是： 70.00%\n"
     ]
    }
   ],
   "source": [
    "def simrate(data, predict):\n",
    "    num = 0\n",
    "    for i in range(len(data)):\n",
    "        if data[i][-1] == predict[i]:\n",
    "            num +=1\n",
    "    return format(num / len(data), '.2%')\n",
    "print(\"ID3分类器对于test1数据集的准确率是：\", simrate(test1, result1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出，用这种方法得到树分类树对于小规模数据的分类效果相对较好。\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 利用$C4.5$算法构建决策树\n",
    "信息增益作为划分准则存在的问题：<br/>\n",
    "信息增益偏向于选择取值较多的特征进行划分。⽐如学号这个特征，每个学生都有一个不同的学号，如果根据学号对样本进行分类，则每个学生都属于不同的类别，这样是没有意义的。而C4.5在生成过程中，用信息增益比来选择特征，可以校正这个问题。<br/>\n",
    "信息增益比 = 惩罚参数 * 信息增益，即 $g_R(D,A) = \\frac{g(D,A)}{H_A(D)}$，其中的$H_A(D)$，对于样本集合D，将当前特征A作为随机变量（取值是特征A的各个特征值），求得的经验熵。<br/>\n",
    "信息增益比本质： 是在信息增益的基础之上乘上一个惩罚参数。特征个数较多时，惩罚参数较小；特征个数较少时，惩罚参数较大。<br/>\n",
    "惩罚参数：数据集D以特征A作为随机变量的熵的倒数，即：将特征A取值相同的样本划分到同一个子集中，$惩罚参数 = \\frac{1}{H_A(D)}=\\frac{1}{-\\sum_{(i = 1)}^{n}\\frac{|D_i|}{|D|}\\log_2\\frac{|D_i|}{|D|}}$ <br/>\n",
    "- 将连续属性离散化<br/>\n",
    "采用二分法，把数据由小到大排列，选择每个区间的中位点位取值，左侧区间为不大于该点的值，右侧区间为大于该点的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Division(data):\n",
    "    ls = data[:]\n",
    "    ls.sort()\n",
    "    result = []\n",
    "    for i in range(len(ls) - 1):\n",
    "        result.append((data[i + 1] + data[i]) / 2)\n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 将数据按照某一种类的属性或者数值的区间重新分类；method = 0 按照区间左侧分类，method = 1 按照区间右侧分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split2(data, index, kind, method):\n",
    "    ls = []\n",
    "    if method == 0:\n",
    "        for temp in data:\n",
    "            if temp[index] <= kind:\n",
    "                t = temp[0 : index]\n",
    "                t = t + temp[index + 1 : ]\n",
    "                ls.append(t)\n",
    "    else:\n",
    "        for temp in data:\n",
    "            if temp[index] > kind:\n",
    "                t = temp[0 : index]\n",
    "                t = t + temp[index + 1 : ]\n",
    "                ls.append(t)\n",
    "    return ls"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 计算信息熵和信息增益并返回最优的分类方式，对数据的每项指标做以下的过程\n",
    "    1. 抽取该项数据的所有信息\n",
    "    2. 计算每一类的信息熵\n",
    "    3. 按照该项数据的类别信息将数据集划分成多个子数据集\n",
    "    4. 计算每个数据集的信息熵\n",
    "    5. 计算该项数据的信息增益比\n",
    "    6. 根据信息增益选择最好的分类项目，返回该项目的类别号\n",
    "    7. 对连续型数据，计算分割值，求出信息增益比最小的点作为分割点返回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseBestFeatureToSplit2(data):\n",
    "    print(data)\n",
    "    base, mm= information(data) #原始的信息熵\n",
    "    info = []\n",
    "    for j in range(len(data[0]) - 1):\n",
    "        dic = {}\n",
    "        for i in data:\n",
    "            current = i[j] #取出最后的结果\n",
    "            if current not in dic.keys(): \n",
    "                dic[current] = 1 #创建一个新的类别\n",
    "            else:\n",
    "                dic[current] += 1 #原有类别+1\n",
    "        result = 0.0\n",
    "        for key in dic:\n",
    "            prob = float(dic[key]) / len(data)\n",
    "            result -= prob * math.log(prob,2) \n",
    "        info.append(result)\n",
    "    best = 0\n",
    "    bestindex = -1\n",
    "    bestpartvalue = None #如果是离散值，使用该值进行分割\n",
    "    for i in range(len(data[0]) - 1):\n",
    "        #抽取该列数据的所有信息\n",
    "        ls = [index[i] for index in data]\n",
    "        feture = set(ls) \n",
    "        #计算该列的信息增益\n",
    "        temp = 0.0\n",
    "        print(type(ls[0]))\n",
    "        if type(ls[0]) == type(\"a\"):#判断是否时离散的\n",
    "            for value in feture:\n",
    "                datatemp = split(data, i, value)\n",
    "                prob = len(datatemp) / float(len(data))\n",
    "                t, mm = information(datatemp)\n",
    "                temp += prob * t\n",
    "        else:\n",
    "            ls.sort()\n",
    "            min = float(\"inf\")\n",
    "            for j in range(len(ls) - 1):\n",
    "                part = (ls[j + 1] + ls[j]) / 2 #计算划分点\n",
    "                left = split2(data, i, part, 0)\n",
    "                right = split2(data, i, part, 1)\n",
    "                temp1, useless = information(left)\n",
    "                temp2, useless = information(right)\n",
    "                temp = len(left) / len(data) * temp1 + len(right) / len(data) * temp2\n",
    "                if temp < min:\n",
    "                    min = temp\n",
    "                    bestpartvalue = part\n",
    "            temp = min\n",
    "        infoGain = base - temp\n",
    "        #根据信息增益挑选 \n",
    "        if info[i] != 0:\n",
    "            if infoGain / info[i] >= best:\n",
    "                best = infoGain / info[i]\n",
    "                bestindex = i\n",
    "    return bestindex, bestpartvalue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['青绿', '蜷缩', '浊响', '清晰', 0.697, '是'], ['乌黑', '蜷缩', '沉闷', '清晰', 0.774, '是'], ['乌黑', '蜷缩', '浊响', '清晰', 0.634, '是'], ['青绿', '蜷缩', '沉闷', '清晰', 0.608, '是'], ['浅白', '蜷缩', '浊响', '清晰', 0.556, '是'], ['青绿', '稍蜷', '浊响', '清晰', 0.403, '是'], ['乌黑', '稍蜷', '浊响', '稍糊', 0.481, '是'], ['乌黑', '稍蜷', '浊响', '清晰', 0.437, '是'], ['乌黑', '稍蜷', '沉闷', '稍糊', 0.666, '否'], ['青绿', '硬挺', '清脆', '清晰', 0.243, '否'], ['浅白', '硬挺', '清脆', '模糊', 0.245, '否'], ['浅白', '蜷缩', '浊响', '模糊', 0.343, '否'], ['青绿', '稍蜷', '浊响', '稍糊', 0.639, '否'], ['浅白', '稍蜷', '沉闷', '稍糊', 0.657, '否'], ['乌黑', '稍蜷', '浊响', '清晰', 0.36, '否'], ['浅白', '蜷缩', '浊响', '模糊', 0.593, '否'], ['青绿', '蜷缩', '沉闷', '稍糊', 0.719, '否']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'float'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 0.3815)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chooseBestFeatureToSplit2(train2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 递归构建$C4.5$决策树\n",
    "- 决策树的生成\n",
    "\t1. 从根节点开始，计算所有可能特征的信息增益，选择信息增益最大的特征作为划分该节点的特征，根据该特征的不同取值建立子节点；\n",
    "\t2. 在对子节点递归地调用以上方法，直到达到停止条件，得到⼀个决策树。\n",
    "- 迭代停止条件\n",
    "    1. 当前结点所有样本都属于同⼀类别；\n",
    "    2. 当前结点的所有属性值都相同，没有剩余属性可用来进一步划分样本；\n",
    "    3. 达到最大树深；\n",
    "    4. 达到叶子结点的最小样本数；\n",
    "- 具体实现\n",
    "    1. 首先取出该数据集的类别信息\n",
    "    2. 统计处类别信息以及数量，如果只有一个类别，返回该类别\n",
    "    3. 计算最优划分的索引\n",
    "    4. 初始化子树\n",
    "    5. 当前已经选择的特征如果是离散的便不再参与分类，将该特征删除；如果是连续的不删除该特征，以分界点构建左子树和右子树\n",
    "    6. 计算剩余特征的集合\n",
    "    7. 对于每个分支，进行递归\n",
    "    8. 返回值为子树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify2(data, labels):\n",
    "    print(labels)\n",
    "    typelist = [index[-1] for index in data] #取出该数据集的分类\n",
    "    nothing, typecount = information(data) #计算出类别种类以及数量\n",
    "    if typecount == len(typelist): #如果只有一个类别\n",
    "        return typelist[0]\n",
    "    bestindex, part = chooseBestFeatureToSplit2(data)  # 最优划分属性的索引\n",
    "    if bestindex == -1:\n",
    "        return \"是\"\n",
    "    if type([t[bestindex] for t in data][0]) == type(\"a\"):#判断是否时离散的\n",
    "        bestlabel = labels[bestindex]\n",
    "        Tree = {bestlabel: {}}\n",
    "        temp = copy.copy(labels)\n",
    "        feature = [example[bestindex] for example in data]\n",
    "        del (temp[bestindex])  # 已经选择的特征不再参与分类，将该类别删除\n",
    "        unique = set(feature)  # 该属性所有可能取值，也就是节点的分支\n",
    "        for i in unique:  \n",
    "            s = temp[:] \n",
    "            Tree[bestlabel][i] = classify2(split(data, bestindex, i), s)\n",
    "    else: #连续的变量\n",
    "        bestlabel = labels[bestindex] + \"<\" + str(part)\n",
    "        Tree = {bestlabel: {}}\n",
    "        temp = labels[:]\n",
    "        del(temp[bestindex])\n",
    "        leftdata = split2(data, bestindex, part, 0)\n",
    "        Tree[bestlabel][\"是\"] = classify2(leftdata, temp)\n",
    "        rightdata = split2(data, bestindex, part, 1)\n",
    "        Tree[bestlabel][\"否\"] = classify2(rightdata, temp)\n",
    "    return Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['色泽', '根蒂', '敲声', '纹理', '密度', '好瓜']\n",
      "[['青绿', '蜷缩', '浊响', '清晰', 0.697, '是'], ['乌黑', '蜷缩', '沉闷', '清晰', 0.774, '是'], ['乌黑', '蜷缩', '浊响', '清晰', 0.634, '是'], ['青绿', '蜷缩', '沉闷', '清晰', 0.608, '是'], ['浅白', '蜷缩', '浊响', '清晰', 0.556, '是'], ['青绿', '稍蜷', '浊响', '清晰', 0.403, '是'], ['乌黑', '稍蜷', '浊响', '稍糊', 0.481, '是'], ['乌黑', '稍蜷', '浊响', '清晰', 0.437, '是'], ['乌黑', '稍蜷', '沉闷', '稍糊', 0.666, '否'], ['青绿', '硬挺', '清脆', '清晰', 0.243, '否'], ['浅白', '硬挺', '清脆', '模糊', 0.245, '否'], ['浅白', '蜷缩', '浊响', '模糊', 0.343, '否'], ['青绿', '稍蜷', '浊响', '稍糊', 0.639, '否'], ['浅白', '稍蜷', '沉闷', '稍糊', 0.657, '否'], ['乌黑', '稍蜷', '浊响', '清晰', 0.36, '否'], ['浅白', '蜷缩', '浊响', '模糊', 0.593, '否'], ['青绿', '蜷缩', '沉闷', '稍糊', 0.719, '否']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'float'>\n",
      "['色泽', '根蒂', '敲声', '密度', '好瓜']\n",
      "[['浅白', '硬挺', '清脆', 0.245, '否'], ['浅白', '蜷缩', '浊响', 0.343, '否'], ['浅白', '蜷缩', '浊响', 0.593, '否']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'float'>\n",
      "['色泽', '根蒂', '敲声', '好瓜']\n",
      "[['浅白', '硬挺', '清脆', '否']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "['色泽', '根蒂', '敲声', '好瓜']\n",
      "[['浅白', '蜷缩', '浊响', '否'], ['浅白', '蜷缩', '浊响', '否']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "['色泽', '根蒂', '敲声', '密度', '好瓜']\n",
      "[['乌黑', '稍蜷', '浊响', 0.481, '是'], ['乌黑', '稍蜷', '沉闷', 0.666, '否'], ['青绿', '稍蜷', '浊响', 0.639, '否'], ['浅白', '稍蜷', '沉闷', 0.657, '否'], ['青绿', '蜷缩', '沉闷', 0.719, '否']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'float'>\n",
      "['色泽', '根蒂', '密度', '好瓜']\n",
      "[['乌黑', '稍蜷', 0.666, '否'], ['浅白', '稍蜷', 0.657, '否'], ['青绿', '蜷缩', 0.719, '否']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'float'>\n",
      "['色泽', '根蒂', '好瓜']\n",
      "[['浅白', '稍蜷', '否']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "['色泽', '根蒂', '好瓜']\n",
      "[['乌黑', '稍蜷', '否'], ['青绿', '蜷缩', '否']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "['色泽', '好瓜']\n",
      "[['乌黑', '否']]\n",
      "<class 'str'>\n",
      "['色泽', '好瓜']\n",
      "[['青绿', '否']]\n",
      "<class 'str'>\n",
      "['色泽', '根蒂', '密度', '好瓜']\n",
      "[['乌黑', '稍蜷', 0.481, '是'], ['青绿', '稍蜷', 0.639, '否']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'float'>\n",
      "['色泽', '根蒂', '好瓜']\n",
      "[['乌黑', '稍蜷', '是']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "['色泽', '根蒂', '好瓜']\n",
      "[['青绿', '稍蜷', '否']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "['色泽', '根蒂', '敲声', '密度', '好瓜']\n",
      "[['青绿', '蜷缩', '浊响', 0.697, '是'], ['乌黑', '蜷缩', '沉闷', 0.774, '是'], ['乌黑', '蜷缩', '浊响', 0.634, '是'], ['青绿', '蜷缩', '沉闷', 0.608, '是'], ['浅白', '蜷缩', '浊响', 0.556, '是'], ['青绿', '稍蜷', '浊响', 0.403, '是'], ['乌黑', '稍蜷', '浊响', 0.437, '是'], ['青绿', '硬挺', '清脆', 0.243, '否'], ['乌黑', '稍蜷', '浊响', 0.36, '否']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'float'>\n",
      "['色泽', '敲声', '密度', '好瓜']\n",
      "[['青绿', '浊响', 0.403, '是'], ['乌黑', '浊响', 0.437, '是'], ['乌黑', '浊响', 0.36, '否']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'float'>\n",
      "['色泽', '敲声', '好瓜']\n",
      "[['乌黑', '浊响', '否']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "['色泽', '敲声', '好瓜']\n",
      "[['青绿', '浊响', '是'], ['乌黑', '浊响', '是']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "['敲声', '好瓜']\n",
      "[['浊响', '是']]\n",
      "<class 'str'>\n",
      "['敲声', '好瓜']\n",
      "[['浊响', '是']]\n",
      "<class 'str'>\n",
      "['色泽', '敲声', '密度', '好瓜']\n",
      "[['青绿', '浊响', 0.697, '是'], ['乌黑', '沉闷', 0.774, '是'], ['乌黑', '浊响', 0.634, '是'], ['青绿', '沉闷', 0.608, '是'], ['浅白', '浊响', 0.556, '是']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'float'>\n",
      "['色泽', '敲声', '好瓜']\n",
      "[['浅白', '浊响', '是']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "['色泽', '敲声', '好瓜']\n",
      "[['青绿', '浊响', '是'], ['乌黑', '沉闷', '是'], ['乌黑', '浊响', '是'], ['青绿', '沉闷', '是']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "['色泽', '好瓜']\n",
      "[['乌黑', '是'], ['青绿', '是']]\n",
      "<class 'str'>\n",
      "['好瓜']\n",
      "[['是']]\n",
      "['好瓜']\n",
      "[['是']]\n",
      "['色泽', '好瓜']\n",
      "[['青绿', '是'], ['乌黑', '是']]\n",
      "<class 'str'>\n",
      "['好瓜']\n",
      "[['是']]\n",
      "['好瓜']\n",
      "[['是']]\n",
      "['色泽', '敲声', '密度', '好瓜']\n",
      "[['青绿', '清脆', 0.243, '否']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "labels2 = [\"色泽\", \"根蒂\", \"敲声\", \"纹理\", \"密度\", \"好瓜\"]\n",
    "tree=classify2(train2,labels2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对测试集利用$C4.5$决策树进行分类\n",
    "- 取出当前树的根节点\n",
    "- 利用跟节点信息查询当前输入数据输入内容\n",
    "- 如果是离散值\n",
    "    1. 如果查询出来的分支是叶节点，返回该值\n",
    "    2. 如果不是叶节点，递归查询子树\n",
    "- 如果是非离散值\n",
    "    1. 取出节点值与现在数据进行比较\n",
    "    2. 如果大于以“否”为标签，否则以“是”为标签\n",
    "    3. 如果查询出来的分支是叶节点，返回该值\n",
    "    4. 如果不是叶节点，递归查询子树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run2(data, tree, labels):\n",
    "    firstStr = list(tree.keys())[0]  # 根节点\n",
    "    firstLabel = firstStr\n",
    "    t = str(firstStr).find('<') #查看是否是连续型\n",
    "    if t > -1:  # 如果是连续型的特征\n",
    "        firstLabel = str(firstStr)[ : t]\n",
    "    secondDict = tree[firstStr]\n",
    "    featIndex = labels.index(firstLabel)  # 跟节点对应的属性\n",
    "    result = ''\n",
    "    for key in list(secondDict.keys()):  # 对每个分支循环\n",
    "        if type(data[featIndex]) == type(\"a\"):\n",
    "            if data[featIndex] == key:  # 测试样本进入某个分支\n",
    "                if type(secondDict[key]).__name__ == 'dict':  # 该分支不是叶子节点，递归\n",
    "                    result = run2(data, secondDict[key], labels)\n",
    "                else:  # 如果是叶子， 返回结果\n",
    "                    result = secondDict[key]\n",
    "        else:\n",
    "            value = float(str(firstStr)[t + 1 : ])\n",
    "            if data[featIndex] <= value:\n",
    "                if type(secondDict['是']).__name__ == 'dict':  # 该分支不是叶子节点，递归\n",
    "                    result = run2(data, secondDict['是'], labels)\n",
    "                else:  # 如果是叶子， 返回结果\n",
    "                    result = secondDict['是']\n",
    "            else:\n",
    "                if type(secondDict['否']).__name__ == 'dict':  # 该分支不是叶子节点，递归\n",
    "                    result = run2(data, secondDict['否'], labels)\n",
    "                else:  # 如果是叶子， 返回结果\n",
    "                    result = secondDict['否']\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['青绿', '蜷缩', '浊响', '清晰', 0.697, '是']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'是'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train2[0])\n",
    "run2(train2[0],tree,labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['色泽', '根蒂', '敲声', '纹理', '密度', '好瓜']\n",
      "[['青绿', '蜷缩', '浊响', '清晰', 0.697, '是'], ['乌黑', '蜷缩', '沉闷', '清晰', 0.774, '是'], ['乌黑', '蜷缩', '浊响', '清晰', 0.634, '是'], ['青绿', '蜷缩', '沉闷', '清晰', 0.608, '是'], ['浅白', '蜷缩', '浊响', '清晰', 0.556, '是'], ['青绿', '稍蜷', '浊响', '清晰', 0.403, '是'], ['乌黑', '稍蜷', '浊响', '稍糊', 0.481, '是'], ['乌黑', '稍蜷', '浊响', '清晰', 0.437, '是'], ['乌黑', '稍蜷', '沉闷', '稍糊', 0.666, '否'], ['青绿', '硬挺', '清脆', '清晰', 0.243, '否'], ['浅白', '硬挺', '清脆', '模糊', 0.245, '否'], ['浅白', '蜷缩', '浊响', '模糊', 0.343, '否'], ['青绿', '稍蜷', '浊响', '稍糊', 0.639, '否'], ['浅白', '稍蜷', '沉闷', '稍糊', 0.657, '否'], ['乌黑', '稍蜷', '浊响', '清晰', 0.36, '否'], ['浅白', '蜷缩', '浊响', '模糊', 0.593, '否'], ['青绿', '蜷缩', '沉闷', '稍糊', 0.719, '否']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'float'>\n",
      "['色泽', '根蒂', '敲声', '密度', '好瓜']\n",
      "[['浅白', '硬挺', '清脆', 0.245, '否'], ['浅白', '蜷缩', '浊响', 0.343, '否'], ['浅白', '蜷缩', '浊响', 0.593, '否']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'float'>\n",
      "['色泽', '根蒂', '敲声', '好瓜']\n",
      "[['浅白', '硬挺', '清脆', '否']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "['色泽', '根蒂', '敲声', '好瓜']\n",
      "[['浅白', '蜷缩', '浊响', '否'], ['浅白', '蜷缩', '浊响', '否']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "['色泽', '根蒂', '敲声', '密度', '好瓜']\n",
      "[['乌黑', '稍蜷', '浊响', 0.481, '是'], ['乌黑', '稍蜷', '沉闷', 0.666, '否'], ['青绿', '稍蜷', '浊响', 0.639, '否'], ['浅白', '稍蜷', '沉闷', 0.657, '否'], ['青绿', '蜷缩', '沉闷', 0.719, '否']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'float'>\n",
      "['色泽', '根蒂', '密度', '好瓜']\n",
      "[['乌黑', '稍蜷', 0.666, '否'], ['浅白', '稍蜷', 0.657, '否'], ['青绿', '蜷缩', 0.719, '否']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'float'>\n",
      "['色泽', '根蒂', '好瓜']\n",
      "[['浅白', '稍蜷', '否']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "['色泽', '根蒂', '好瓜']\n",
      "[['乌黑', '稍蜷', '否'], ['青绿', '蜷缩', '否']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "['色泽', '好瓜']\n",
      "[['乌黑', '否']]\n",
      "<class 'str'>\n",
      "['色泽', '好瓜']\n",
      "[['青绿', '否']]\n",
      "<class 'str'>\n",
      "['色泽', '根蒂', '密度', '好瓜']\n",
      "[['乌黑', '稍蜷', 0.481, '是'], ['青绿', '稍蜷', 0.639, '否']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'float'>\n",
      "['色泽', '根蒂', '好瓜']\n",
      "[['乌黑', '稍蜷', '是']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "['色泽', '根蒂', '好瓜']\n",
      "[['青绿', '稍蜷', '否']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "['色泽', '根蒂', '敲声', '密度', '好瓜']\n",
      "[['青绿', '蜷缩', '浊响', 0.697, '是'], ['乌黑', '蜷缩', '沉闷', 0.774, '是'], ['乌黑', '蜷缩', '浊响', 0.634, '是'], ['青绿', '蜷缩', '沉闷', 0.608, '是'], ['浅白', '蜷缩', '浊响', 0.556, '是'], ['青绿', '稍蜷', '浊响', 0.403, '是'], ['乌黑', '稍蜷', '浊响', 0.437, '是'], ['青绿', '硬挺', '清脆', 0.243, '否'], ['乌黑', '稍蜷', '浊响', 0.36, '否']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'float'>\n",
      "['色泽', '敲声', '密度', '好瓜']\n",
      "[['青绿', '浊响', 0.403, '是'], ['乌黑', '浊响', 0.437, '是'], ['乌黑', '浊响', 0.36, '否']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'float'>\n",
      "['色泽', '敲声', '好瓜']\n",
      "[['乌黑', '浊响', '否']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "['色泽', '敲声', '好瓜']\n",
      "[['青绿', '浊响', '是'], ['乌黑', '浊响', '是']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "['敲声', '好瓜']\n",
      "[['浊响', '是']]\n",
      "<class 'str'>\n",
      "['敲声', '好瓜']\n",
      "[['浊响', '是']]\n",
      "<class 'str'>\n",
      "['色泽', '敲声', '密度', '好瓜']\n",
      "[['青绿', '浊响', 0.697, '是'], ['乌黑', '沉闷', 0.774, '是'], ['乌黑', '浊响', 0.634, '是'], ['青绿', '沉闷', 0.608, '是'], ['浅白', '浊响', 0.556, '是']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'float'>\n",
      "['色泽', '敲声', '好瓜']\n",
      "[['浅白', '浊响', '是']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "['色泽', '敲声', '好瓜']\n",
      "[['青绿', '浊响', '是'], ['乌黑', '沉闷', '是'], ['乌黑', '浊响', '是'], ['青绿', '沉闷', '是']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "['色泽', '好瓜']\n",
      "[['乌黑', '是'], ['青绿', '是']]\n",
      "<class 'str'>\n",
      "['好瓜']\n",
      "[['是']]\n",
      "['好瓜']\n",
      "[['是']]\n",
      "['色泽', '好瓜']\n",
      "[['青绿', '是'], ['乌黑', '是']]\n",
      "<class 'str'>\n",
      "['好瓜']\n",
      "[['是']]\n",
      "['好瓜']\n",
      "[['是']]\n",
      "['色泽', '敲声', '密度', '好瓜']\n",
      "[['青绿', '清脆', 0.243, '否']]\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'float'>\n",
      "生成决策树如下: {'纹理': {'模糊': {'密度<0.29400000000000004': {'是': '是', '否': '是'}}, '稍糊': {'敲声': {'沉闷': {'密度<0.6615': {'是': '是', '否': {'根蒂': {'稍蜷': '是', '蜷缩': '是'}}}}, '浊响': {'密度<0.56': {'是': '是', '否': '是'}}}}, '清晰': {'根蒂': {'稍蜷': {'密度<0.3815': {'是': '是', '否': {'色泽': {'乌黑': '是', '青绿': '是'}}}}, '蜷缩': {'密度<0.5820000000000001': {'是': '是', '否': {'敲声': {'沉闷': {'色泽': {'乌黑': '是', '青绿': '是'}}, '浊响': {'色泽': {'乌黑': '是', '青绿': '是'}}}}}}, '硬挺': '是'}}}}\n",
      "['是', '是', '是', '是', '是']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def getresult2(train, test, labels):\n",
    "    ls = []\n",
    "    tree = classify2(train, labels)\n",
    "    print(\"生成决策树如下:\", tree)\n",
    "    for index in test:\n",
    "        ls.append(run2(index, tree, labels))\n",
    "    return ls\n",
    "\n",
    "labels2 = [\"色泽\", \"根蒂\", \"敲声\", \"纹理\", \"密度\", \"好瓜\"]\n",
    "result2 = getresult2(train2, test2, labels2)\n",
    "print(result2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算准确率\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C4.5分类器对于test2数据集的准确率是： 60.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"C4.5分类器对于test2数据集的准确率是：\", simrate(test2, result2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出，在不剪枝的情况下C4.5预测的准确率稍较为一般"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '西瓜数据集2.0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 81\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[39mreturn\u001b[39;00m class_label\n\u001b[0;32m     79\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     80\u001b[0m     \u001b[39m#读取数据\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m     data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m西瓜数据集2.0.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     83\u001b[0m     \u001b[39m#统计每个特征的取值情况作为全局变量\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     column_count \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m([(ds, \u001b[39mlist\u001b[39m(pd\u001b[39m.\u001b[39munique(data[ds]))) \u001b[39mfor\u001b[39;00m ds \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39miloc[:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mcolumns])\n",
      "File \u001b[1;32me:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32me:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32me:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_engine(f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine)\n",
      "File \u001b[1;32me:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcompression\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmemory_map\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mencoding_errors\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mstorage_options\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32me:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[39m=\u001b[39mioargs\u001b[39m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[39m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '西瓜数据集2.0.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#计算信息熵\n",
    "def cal_information_entropy(data):\n",
    "    data_label = data.iloc[:,-1]\n",
    "    label_class =data_label.value_counts() #总共有多少类\n",
    "    Ent = 0\n",
    "    for k in label_class.keys():\n",
    "        p_k = label_class[k]/len(data_label)\n",
    "        Ent += -p_k*np.log2(p_k)\n",
    "    return Ent\n",
    "\n",
    "#计算给定数据属性a的信息增益\n",
    "def cal_information_gain(data, a):\n",
    "    Ent = cal_information_entropy(data)\n",
    "    feature_class = data[a].value_counts() #特征有多少种可能\n",
    "    gain = 0\n",
    "    for v in feature_class.keys():\n",
    "        weight = feature_class[v]/data.shape[0]\n",
    "        Ent_v = cal_information_entropy(data.loc[data[a] == v])\n",
    "        gain += weight*Ent_v\n",
    "    return Ent - gain\n",
    "\n",
    "#获取标签最多的那一类\n",
    "def get_most_label(data):\n",
    "    data_label = data.iloc[:,-1]\n",
    "    label_sort = data_label.value_counts(sort=True)\n",
    "    return label_sort.keys()[0]\n",
    "\n",
    "#挑选最优特征，即信息增益最大的特征\n",
    "def get_best_feature(data):\n",
    "    features = data.columns[:-1]\n",
    "    res = {}\n",
    "    for a in features:\n",
    "        temp = cal_information_gain(data, a)\n",
    "        res[a] = temp\n",
    "    res = sorted(res.items(),key=lambda x:x[1],reverse=True)\n",
    "    return res[0][0]\n",
    "\n",
    "##将数据转化为（属性值：数据）的元组形式返回，并删除之前的特征列\n",
    "def drop_exist_feature(data, best_feature):\n",
    "    attr = pd.unique(data[best_feature])\n",
    "    new_data = [(nd, data[data[best_feature] == nd]) for nd in attr]\n",
    "    new_data = [(n[0], n[1].drop([best_feature], axis=1)) for n in new_data]\n",
    "    return new_data\n",
    "\n",
    "#创建决策树\n",
    "def create_tree(data):\n",
    "    data_label = data.iloc[:,-1]\n",
    "    if len(data_label.value_counts()) == 1: #只有一类\n",
    "        return data_label.values[0]\n",
    "    if all(len(data[i].value_counts()) == 1 for i in data.iloc[:,:-1].columns): #所有数据的特征值一样，选样本最多的类作为分类结果\n",
    "        return get_most_label(data)\n",
    "    best_feature = get_best_feature(data) #根据信息增益得到的最优划分特征\n",
    "    Tree = {best_feature:{}} #用字典形式存储决策树\n",
    "    exist_vals = pd.unique(data[best_feature]) #当前数据下最佳特征的取值\n",
    "    if len(exist_vals) != len(column_count[best_feature]): #如果特征的取值相比于原来的少了\n",
    "        no_exist_attr = set(column_count[best_feature]) - set(exist_vals) #少的那些特征\n",
    "        for no_feat in no_exist_attr:\n",
    "            Tree[best_feature][no_feat] = get_most_label(data) #缺失的特征分类为当前类别最多的\n",
    "\n",
    "    for item in drop_exist_feature(data,best_feature): #根据特征值的不同递归创建决策树\n",
    "        Tree[best_feature][item[0]] = create_tree(item[1])\n",
    "    return Tree\n",
    "\n",
    "#{'纹理': {'清晰': {'根蒂': {'蜷缩': 1, '稍蜷': {'色泽': {'青绿': 1, '乌黑': {'触感': {'硬滑': 1, '软粘': 0}}}}, '硬挺': 0}}, '稍糊': {'触感': {'软粘': 1, '硬滑': 0}}, '模糊': 0}}\n",
    "def predict(Tree , test_data):\n",
    "    first_feature = list(Tree.keys())[0]\n",
    "    second_dict = Tree[first_feature]\n",
    "    input_first = test_data.get(first_feature)\n",
    "    input_value = second_dict[input_first]\n",
    "    if isinstance(input_value , dict): #判断分支还是不是字典\n",
    "        class_label = predict(input_value, test_data)\n",
    "    else:\n",
    "        class_label = input_value\n",
    "    return class_label\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #读取数据\n",
    "    data = pd.read_csv('西瓜数据集2.0.csv')\n",
    "\n",
    "    #统计每个特征的取值情况作为全局变量\n",
    "    column_count = dict([(ds, list(pd.unique(data[ds]))) for ds in data.iloc[:, :-1].columns])\n",
    "\n",
    "    #创建决策树\n",
    "    dicision_Tree = create_tree(data)\n",
    "    print(dicision_Tree)\n",
    "    #测试数据\n",
    "    test_data_1 = {'色泽':'青绿','根蒂':'蜷缩','敲声':'浊响','纹理':'稍糊','脐部':'凹陷','触感':'硬滑'}\n",
    "    test_data_2 = {'色泽': '乌黑', '根蒂': '稍蜷', '敲声': '浊响', '纹理': '清晰', '脐部': '凹陷', '触感': '硬滑'}\n",
    "    result = predict(dicision_Tree,test_data_2)\n",
    "    print('分类结果为'+'好瓜'if result == 1 else '坏瓜')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
